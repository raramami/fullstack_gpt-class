{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi'), AIMessage(content='How are you ?')]}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)   #챗모델(Human, AI) 을 위한 거라면 return_messages=True 로 \n",
    "memory.save_context({\"input\":\"Hi\"},{\"output\":\"How are you ?\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi'),\n",
       "  AIMessage(content='How are you ?'),\n",
       "  HumanMessage(content='Hi'),\n",
       "  AIMessage(content='How are you ?')]}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "memory.save_context({\"input\":\"Hi\"},{\"output\":\"How are you ?\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi'),\n",
       "  AIMessage(content='How are you ?'),\n",
       "  HumanMessage(content='Hi'),\n",
       "  AIMessage(content='How are you ?'),\n",
       "  HumanMessage(content='Hi'),\n",
       "  AIMessage(content='How are you ?')]}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.save_context({\"input\":\"Hi\"},{\"output\":\"How are you ?\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory  #특정 메모리만 사이즈를 정해서 저장 (예:최근 5개의 대화 기록만 저장)\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    return_messages=True,\n",
    "    k=4\n",
    ")\n",
    "\n",
    "def add_messages(input,output):\n",
    "    memory.save_context({\"input\":input},{\"output\":output})\n",
    "\n",
    "add_messages(1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_messages(2,2)\n",
    "add_messages(3,3)\n",
    "add_messages(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='1'),\n",
       "  AIMessage(content='1'),\n",
       "  HumanMessage(content='2'),\n",
       "  AIMessage(content='2'),\n",
       "  HumanMessage(content='3'),\n",
       "  AIMessage(content='3'),\n",
       "  HumanMessage(content='4'),\n",
       "  AIMessage(content='4')]}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_messages(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='2'),\n",
       "  AIMessage(content='2'),\n",
       "  HumanMessage(content='3'),\n",
       "  AIMessage(content='3'),\n",
       "  HumanMessage(content='4'),\n",
       "  AIMessage(content='4'),\n",
       "  HumanMessage(content='5'),\n",
       "  AIMessage(content='5')]}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "def add_messages(input,output):\n",
    "    memory.save_context({\"input\":input},{\"output\":output})\n",
    "\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})\n",
    "\n",
    "add_messages(\"Hi, I'm sunny , I live in Korea\",\"Wow, That's so cool !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_messages(\"Korea is very beautiful country\",\"I wish I could go!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"The human introduces themselves as Sunny from Korea. The AI responds by expressing admiration for Sunny's location and wishes it could go visit Korea because it is a very beautiful country.\"}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=150,\n",
    "    return_messages=True, \n",
    ")\n",
    "\n",
    "def add_messages(input,output):\n",
    "    memory.save_context({\"input\":input},{\"output\":output})\n",
    "\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})\n",
    "\n",
    "add_messages(\"Hi, I'm sunny , I live in Korea\",\"Wow, That's so cool !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi, I'm sunny , I live in Korea\"),\n",
       "  AIMessage(content=\"Wow, That's so cool !\")]}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_messages(\"Korea is very beautiful country\",\"I wish I could go!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi, I'm sunny , I live in Korea\"),\n",
       "  AIMessage(content=\"Wow, That's so cool !\"),\n",
       "  HumanMessage(content='Korea is very beautiful country'),\n",
       "  AIMessage(content='I wish I could go!')]}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_messages(\"How far is France from Argentina ?\",\"I don't know. Super far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi, I'm sunny , I live in Korea\"),\n",
       "  AIMessage(content=\"Wow, That's so cool !\"),\n",
       "  HumanMessage(content='Korea is very beautiful country'),\n",
       "  AIMessage(content='I wish I could go!'),\n",
       "  HumanMessage(content='How far is France from Argentina ?'),\n",
       "  AIMessage(content=\"I don't know. Super far!\")]}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.memory import ConversationKGMemory  # KG : Knowledge Graph , Entity 기준으로 정보를 만들어 감 \n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationKGMemory(\n",
    "    llm=llm,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "def add_messages(input,output):\n",
    "    memory.save_context({\"input\":input},{\"output\":output})\n",
    "\n",
    "add_messages(\"Hi, I'm Sunny , I live in Korea.\",\"Wow, Nice to see you!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On Sunny: Sunny is human. Sunny lives in Korea.')]}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({\"input\":\"who is Sunny\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_messages(\"Sunny likes Bibimbaba.\",\"Wow, That looks Yumm!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On Sunny: Sunny is human. Sunny lives in Korea. Sunny likes Bibimbaba.')]}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({\"input\":\"what does Sunny like ?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to human.\n",
      "Human: My name is Sunny.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello Sunny! How can I assist you today?'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chains import LLMChain    #off-the-shelf LLM: 자동으로 LLM 으로  응답값을 가져오고 메모리를 업데이트 하기 위해 (한마디로 기존 템플릿을 쉽게 갖다 쓰는 것) \n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm = llm,\n",
    "    max_token_limit=200,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "    You are a helpful AI talking to human .\n",
    "\n",
    "    {chat_history}\n",
    "    Human:{question}\n",
    "    You: \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are a helpful AI talking to human.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),    \n",
    "    (\"human\",\"{question}\")\n",
    "    ])\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    #prompt=PromptTemplate.from_template(template),\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "\n",
    ")\n",
    "\n",
    "chain.predict(question=\"My name is Sunny.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to human.\n",
      "Human: My name is Sunny.\n",
      "AI: Hello Sunny! How can I assist you today?\n",
      "Human: I live in Seoul.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's great! Seoul is a vibrant city with a rich history and culture. Is there anything specific you'd like to know or talk about regarding Seoul?\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"I live in Seoul.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to human.\n",
      "Human: My name is Sunny.\n",
      "AI: Hello Sunny! How can I assist you today?\n",
      "Human: I live in Seoul.\n",
      "AI: That's great! Seoul is a vibrant city with a rich history and culture. Is there anything specific you'd like to know or talk about regarding Seoul?\n",
      "Human: What is name ?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Your name is Sunny. It's a lovely name! Is there anything else you would like to know or discuss?\""
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"What is name ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='My name is Sunny.'),\n",
       "  AIMessage(content='Hello Sunny! How can I assist you today?'),\n",
       "  HumanMessage(content='I live in Seoul.'),\n",
       "  AIMessage(content=\"That's great! Seoul is a vibrant city with a rich history and culture. Is there anything specific you'd like to know or talk about regarding Seoul?\"),\n",
       "  HumanMessage(content='What is name ?'),\n",
       "  AIMessage(content=\"Your name is Sunny. It's a lovely name! Is there anything else you would like to know or discuss?\")]}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm = llm,\n",
    "    max_token_limit=200,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are a helpful AI talking to human.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),    \n",
    "    (\"human\",\"{question}\")\n",
    "    ])\n",
    "\n",
    "def load_memory(_):\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "chain = RunnablePassthrough.assign(history=load_memory) | prompt | llm   # 프롬프트가 포맷되는 체인 실행전에 함수를 실행시키는 방법 \n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke(\n",
    "        {\n",
    "        \"question\": \"My name is Sunny \"\n",
    "        }\n",
    "    )\n",
    "    memory.save_context({\"input\":question},{\"output\":result.content})\n",
    "    print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hello Sunny! How can I assist you today?'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"My name is Nico.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='I apologize for the mistake, Sunny. How can I assist you today?'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"What is my name\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
