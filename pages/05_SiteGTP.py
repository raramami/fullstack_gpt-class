from langchain.document_loaders import AsyncChromiumLoader,SitemapLoader
from langchain.document_transformers import Html2TextTransformer
from langchain.text_splitter import RecursiveCharacterTextSplitter
import streamlit as st



def parse_page(soup):
    header = soup.find("header")
    footer = soup.find("footer")
    if header:
        header.decompose()
        # text = header.get_text()
        # return text
    if footer:
        footer.decompose()
    return (
            str(soup.get_text())
            .replace("\n"," ")
            .replace("nExplore"," ")
            )

@st.cache_data(show_spinner="Loading website..")
def load_website(url):
    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
        chunk_size=1000,
        chunk_overlap=200,
    )
    loader = SitemapLoader(url,
                           filter_urls=[r"^(.*\/science\/).*",],
                           parsing_function=parse_page)
    loader.requests_per_second = 1  # ì°¨ë‹¨ë‹¹í•˜ì§€ ì•Šë„ë¡ 1ì´ˆë‹¨ìœ„ë¡œ ìš”ì²­ì‹œê°„ ì„¤ì • 
    docs = loader.load_and_split(text_splitter=splitter)
    #st.write(docs)   #Fetching pages ë¬¸êµ¬ê°€ í„°ë¯¸ë„ ì½˜ì†”ì— ë³´ì„ .
    return docs 

st.set_page_config(
    page_title="Site GPT",
    page_icon="ğŸ‘©ğŸ»â€ğŸ’»",
)

html2text_transformer = Html2TextTransformer()

st.title("Site GPT")

with st.sidebar:
    url = st.text_input("Write down a url",placeholder="https://example.com")


if url:
    #async chromium loader : playwright install ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜ 
    # loader = AsyncChromiumLoader(url)
    # docs = loader.load()
    # transformed = html2text_transformer.transform_documents(docs)
    # st.write(docs)

    # https://openai.com/index/frontier-risk-and-preparedness/

    if ".xml" not in url:
        with st.sidebar:
            st.error("Pls write down a sitemap url . ")
            #https://deepmind.google/sitemap.xml

    else:
       docs = load_website(url)
       st.write(docs)